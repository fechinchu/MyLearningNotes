#  Redis高级

# 1. Redis的常用数据类型

* String
* List
* Hash
* Set
* ZSet

~~~java
public class JedisTests {

    // ------------------------ jedis 工具直连演示
    // jedis和redis命令名称匹配度最高,最为简洁,学习难度最低

    // 列表~ 集合数据存储~ java.util.List,java.util.Stack
    // 生产者消费者(简单MQ)
    public static void list() {
        Jedis jedis = new Jedis("127.0.0.1", 6379);
        // 插入数据1 --- 2 --- 3
        jedis.rpush("queue_1", "1");
        jedis.rpush("queue_1", "2", "3");
        //这里的参数start:0,stop:-1表示全部数据
        // 可以通过Irange命令,从某个元素开始读取多少个元素,可以基于list实现分页查询.
        List<String> strings = jedis.lrange("queue_1", 0, -1);
        for (String string : strings) {
            //1,2,3
            System.out.println(string);
        }

        // 消费者线程简例
        while (true) {
            String item = jedis.lpop("queue_1");
            if (item == null) break;
            //1,2,3
            System.out.println(item);
        }

        jedis.close();
    }

    // 类似：在redis里面存储一个hashmap
    // 推荐的方式,无特殊需求是,一般的缓存都用这个
    public static void hashTest() {
        HashMap<String, Object> user = new HashMap<>();
        user.put("name", "tony");
        user.put("age", 18);
        user.put("userId", 10001);
        //{name=tony, userId=10001, age=18}
        System.out.println(user);

        Jedis jedis = new Jedis("127.0.0.1", 6379);
        jedis.hset("user_10001", "name", "tony");
        jedis.hset("user_10001", "age", "18");
        jedis.hset("user_10001", "userId", "10001");

        // {name=tony, userId=10001, age=18}
        System.out.println(jedis.hgetAll("user_10001"));
        jedis.close();
    }

    // 用set实现(交集 并集)
    // 交集示例： 共同关注的好友
    // 并集示例：
    public static void setTest() {
        // 取出两个人共同关注的好友
        Jedis jedis = new Jedis("127.0.0.1", 6379);
        // 每个人维护一个set
        jedis.sadd("user_A", "userC", "userD", "userE");
        jedis.sadd("user_B", "userC", "userE", "userF");
        // 取出共同关注
        Set<String> sinter = jedis.sinter("user_A", "user_B");
        //[userC, userE]
        System.out.println(sinter);

        // 检索给某一个帖子点赞/转发的
        jedis.sadd("trs_tp_1001", "userC", "userD", "userE");
        jedis.sadd("star_tp_1001", "userE", "userF");
        // 取出共同人群
        //[userC, userD, userE, userF]
        Set<String> union = jedis.sunion("star_tp_1001", "trs_tp_1001");
        System.out.println(union);

        jedis.close();
    }

    // 游戏排行榜
    public static void zsetTest() {
        Jedis jedis = new Jedis("127.0.0.1", 6379);
        String ranksKeyName = "exam_rank";
      	//zadd第二个参数是score,用score进行的排序
        jedis.zadd(ranksKeyName, 100.0, "tony");
        jedis.zadd(ranksKeyName, 82.0, "allen");
        jedis.zadd(ranksKeyName, 90, "mengmeng");
        jedis.zadd(ranksKeyName, 96, "netease");
        jedis.zadd(ranksKeyName, 89, "ali");
        //start:0,stop:2
        Set<String> stringSet = jedis.zrevrange(ranksKeyName, 0, 2);
        System.out.println("返回前三名:");
        //tony,netease,mengmeng
        for (String s : stringSet) {
            System.out.println(s);
        }

        Long zcount = jedis.zcount(ranksKeyName, 85, 100);
        //min 85,max:100 超过85分的数量为4
        System.out.println("超过85分的数量 " + zcount);

        jedis.close();
    }
}
~~~

# 2.持久化的方式

* **RDB持久化方式**能够在指定的时间间隔对数据进行快照存储;
* **AOF(append only file)持久化方式**记录每次对服务器写的操作,当服务器重启的时候会重新执行这些命令来恢复原始的数据;

## 2.1.RDB方式

客户端直接通过命令BGSAVE或者SAVE来创建一个内存快照

* BGSAVE调用fork来创建一个子进程,子进程负责将快照写入磁盘,而父进程仍然继续处理命令;
* SAVE执行SAVE命令的过程中,不再响应其他命令;

在redis.conf中调整save配置选项,当在规定时间内,redis发生了写操作的个数满足条件会触发BGSAVE命令;

![image-20200526140434229](https://fechin-leyou.oss-cn-beijing.aliyuncs.com/PicGo/image-20200526140434229.png)

### 2.1.1.RDB的优点

1. RDB会生成多个数据文件，每个数据文件都代表了某一个时刻中redis的数据，这种多个数据文件的方式，非常适合做冷备，可以将这种完整的数据文件发送到一些远程的安全存储上去，比如说Amazon的S3云服务上去，在国内可以是阿里云的ODPS分布式存储上，以预定好的备份策略来定期备份redis中的数据;

2. RDB对redis对外提供的读写服务，影响非常小，可以让redis保持高性能，因为redis主进程只需要fork一个子进程，让子进程执行磁盘IO操作来进行RDB持久化即可;

3. 相对于AOF持久化机制来说，直接基于RDB数据文件来重启和恢复redis进程，更加快速;

### 2.2.2.RDB的缺点

1. 如果想要在redis故障时，尽可能少的丢失数据，那么RDB没有AOF好。一般来说，RDB数据快照文件，都是每隔5分钟，或者更长时间生成一次，这个时候就得接受一旦redis进程宕机，那么会丢失最近5分钟的数据;

2. RDB每次在fork子进程来执行RDB快照数据文件生成的时候，如果数据文件特别大，可能会导致对客户端提供的服务暂停数毫秒，或者甚至数秒;

## 2.2.AOF方式

![image-20200526140652123](https://fechin-leyou.oss-cn-beijing.aliyuncs.com/PicGo/image-20200526140652123.png)

![image-20200526140732823](https://fechin-leyou.oss-cn-beijing.aliyuncs.com/PicGo/image-20200526140732823.png)

开启AOF持久化:

* `appendonly yes`

AOF策略调整:

* `appendfsync always`:每次有数据修改发生时都会写入AOF文件
* `appendfsync everysec`:每秒钟同步一次,该策略为AOF的缺省策略;
* `appendfsync no`:从不同步,高效但是数据不会被持久化;

### 2.2.1.AOF的优点

1. AOF可以更好的保护数据不丢失，一般AOF会每隔1秒，通过一个后台线程执行一次fsync操作，最多丢失1秒钟的数据
2. AOF日志文件以append-only模式写入，所以没有任何磁盘寻址的开销，写入性能非常高，而且文件不容易破损，即使文件尾部破损，也很容易修复
3. AOF日志文件即使过大的时候，出现后台重写操作，也不会影响客户端的读写。因为在rewrite log的时候，会对其中的指导进行压缩，创建出一份需要恢复数据的最小日志出来。再创建新日志文件的时候，老的日志文件还是照常写入。当新的merge后的日志文件ready的时候，再交换新老日志文件即可。
4. AOF日志文件的命令通过非常可读的方式进行记录，这个特性非常适合做灾难性的误删除的紧急恢复。比如某人不小心用flushall命令清空了所有数据，只要这个时候后台rewrite还没有发生，那么就可以立即拷贝AOF文件，将最后一条flushall命令给删了，然后再将该AOF文件放回去，就可以通过恢复机制，自动恢复所有数据

### 2.2.2.AOF的缺点

1. 对于同一份数据来说，AOF日志文件通常比RDB数据快照文件更大
2. AOF开启后，支持的写QPS会比RDB支持的写QPS低，因为AOF一般会配置成每秒fsync一次日志文件，当然，每秒一次fsync，性能也还是很高的
3. 以前AOF发生过bug，就是通过AOF记录的日志，进行数据恢复的时候，没有恢复一模一样的数据出来。所以说，类似AOF这种较为复杂的基于命令日志/merge/回放的方式，比基于RDB每次持久化一份完整的数据快照文件的方式，更加脆弱一些，容易有bug。不过AOF就是为了避免rewrite过程导致的bug，因此每次rewrite并不是基于旧的指令日志进行merge的，而是基于当时内存中的数据进行指令的重新构建，这样健壮性会好很多。

## 2.3.RDB和AOF如何选择

综合使用AOF和RDB两种持久化机制，用AOF来保证数据不丢失，作为数据恢复的第一选择; 用RDB来做不同程度的冷备，在AOF文件都丢失或损坏不可用的时候，还可以使用RDB来进行快速的数据恢复.

# 3.Redis线程模型

![image-20210712201356714](https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210712201356714.png)

## 3.1.文件事件处理器

Redis基于Reactor模式开发了网络事件处理器,这个处理器叫做文件事件处理器,file event handler.**这个文件事件处理器是单线程的**,Redis才叫做单线程模型,采用IO多路复用机制同时监听多个socket,根据socket上的事件来选择对应的事件处理器来处理这个事件.

文件事件处理器的结构:

* 多个socket;
* IO多路复用程序;
* 文件事件分派器;
* 事件处理器(连接应答处理器,命令请求处理器,命令回复处理器);

## 3.2.一次客户端与Redis的完整通信过程

**建立连接**

1. 首先,redis 服务端进程初始化的时候,会将 server socket 的 AE_READABLE 事件与连接应答处理器关联。
2. 客户端 socket01 向 redis 进程的 server socket 请求建立连接,此时 server socket 会产生一个 AE_READABLE 事件,IO 多路复用程序监听到 server socket 产生的事件后,将该 socket 压入队列中。
3. 文件事件分派器从队列中获取 socket,交给连接应答处理器。
4. 连接应答处理器会创建一个能与客户端通信的 socket01,并将该 socket01 的 AE_READABLE 事件与命令请求处理器关联。

**执行一个set请求**

1. 客户端发送了一个 set key value 请求,此时 redis 中的 socket01 会产生 AE_READABLE 事件,IO 多路复用程序将 socket01 压入队列,
2. 此时事件分派器从队列中获取到 socket01 产生的 AE_READABLE 事件,由于前面 socket01 的 AE_READABLE 事件已经与命令请求处理器关联,
3. 因此事件分派器将事件交给命令请求处理器来处理。命令请求处理器读取 socket01 的 key value 并在自己内存中完成 key value 的设置。
4. 操作完成后,它会将 socket01 的 AE_WRITABLE 事件与命令回复处理器关联。
5. 如果此时客户端准备好接收返回结果了,那么 redis 中的 socket01 会产生一个 AE_WRITABLE 事件,同样压入队列中,
6. 事件分派器找到相关联的命令回复处理器,由命令回复处理器对 socket01 输入本次操作的一个结果,比如 ok,之后解除 socket01 的 AE_WRITABLE 事件与命令回复处理器的关联。

![image-20210712203348619](https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210712203348619.png)

## 3.3.为什么Redis单线程还能支持高并发

1. 存内存操作;
2. 核心是基于非阻塞的IO多路复用机制;
3. 单线程避免了多线程的频繁上下文切换问题;

# 4.Redis内存管理

## 4.1.过期数据的处理策略

* 主动处理(redis主动触发检测key是否过期),redis默认100ms执行一次,过程如下;

  1. 从具有相关过期的密钥集中测试20个随机密钥;

  2. 删除找到的所有密钥已过期;
  3. 如果超过25%的密钥已过期,从步骤一开始;

* 被动处理:
  * 每次访问key的时候,发现超时后被动过期,清理掉;

那么**数据恢复阶段过期数据的处理策略**:

* RDB方式
  * 过期的key不会被持久化到文件中;
  * 载入时过期的key,会通过redis的主动和被动方式清理掉;
* AOF方式
  * 当redis使用AOF方式持久化,每次遇到过期的key,redis会追加一条DEL命令到AOF文件;也就是说只要我们顺序载入执行AOF命令文件就会删除过期的键;

## 4.2.Redis内存淘汰策略

![image-20200526151232550](https://fechin-leyou.oss-cn-beijing.aliyuncs.com/PicGo/image-20200526151232550.png)

### 4.2.1.LRU算法

LRU(Least recently used,最近最少使用):根据数据的历史访问记录来进行淘汰数据;

* 核心思想:如果数据最近被访问过,那么将来被访问的几率也更高;
* 注意:Redis的LRU算法并非完整的思想,完整的LRU实现需要太多的内存;
* 方法:通过对少量keys进行取样(50%),然后回收其中一个最好的key.配置方式:`maxmemory-samples 5`;

### 4.2.2.LFU算法

LFU(Least Frequently Used)根据数的历史访问频率来淘汰数据;

* 核心思想:如果数据过去被访问多次,那么将来被访问的频率也更高;
* Redis实现的是近似的实现,每次对key进行访问时,用基于概率的对数计算器来记录访问次数,同时这个计数器会随着时间推移而减小;
* 启用LFU算法后,可以使用热点数据分析功能`redis-cli --hotkeys`;

# 5.缓存雪崩,缓存穿透,缓存击穿

## 5.1.缓存雪崩

* 事前:Redis高可用,避免全盘崩溃;
* 事中:本地ehache缓存+hystrix限流&降级,避免MySQL被打死;
* 事后:Redis持久化,快速恢复缓存数据;

![image-20200527151531365](https://fechin-leyou.oss-cn-beijing.aliyuncs.com/PicGo/image-20200527151531365.png)

## 5.2.缓存穿透

![image-20200527152119221](https://fechin-leyou.oss-cn-beijing.aliyuncs.com/PicGo/image-20200527152119221.png)

## 5.3.缓存击穿

缓存击穿是指缓存中没有但数据库中有的数据,一般是缓存时间到期,这时由于并发用户特别多,同时读缓存没读到数据,又同时去数据库去取数据,引起数据库压力瞬间增大,造成过大压力

* 解决方法
  1. 设置热点数据永不过期;
  2. 加互斥锁(如果缓存中不存在数据,去请求数据库的时候加上互斥锁);

# 6.缓存与数据库双写一致问题 

数据的一致性包含两种情况:

* 缓存中有数据.那么,缓存的数据值需要和数据库中的值相同;
* 缓存中本身没有数据,那么,数据库中的值必须是最新值;

不属于这两种情况的,就属于缓存和数据库的数据不一致问题了;

对于读写缓存来说,如果要对数据进行增删改,就需要在缓存中进行,同时还要根据采取的写会策略,决定是否同步写到数据库中,策略如下:

* 同步直写策略:写缓存时,也同步写数据库,缓存和数据库中的数据一致;
* 异步写回策略:写缓存时不同步写缓存,等到数据从缓存中淘汰时,再写回数据库.使用这种策略时候,如果数据还没有写会数据库,缓存就发生了故障.那么此时数据库就没有最新的数据了;

对于只读缓存来说，如果有数据新增，会直接写入数据库；而有数据删改时，就需要把只读缓存中的数据标记为无效。这样一来，应用后续再访问这些增删改的数据时，因为缓存中没有相应的数据，就会发生缓存缺失。此时，应用再从数据库中把数据读入缓存，这样后续再访问数据时，就能够直接从缓存中读取了。

出现问题如下:

<img src="https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210720103237371.png" alt="image-20210720103237371" style="zoom:50%;" />

## 6.1.先删除缓存,再更新数据库情况

假设线程A删除缓存值后,还没有来得及更新数据库(比如有网络延迟),线程B就开始读数据了,那么这个时候,线程B会发现缓存缺失,就只能去数据库读取,带来两个问题;

<img src="https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210720110637676.png" alt="image-20210720110637676" style="zoom: 33%;" />

**解决方案:在线程A更新完数据库值后,可以让它先sleep一小段时间,再进行一次缓存删除**;

之所以要加上 sleep 的这段时间，就是为了让线程 B 能够先从数据库读取数据，再把缺失的数据写入缓存，然后，线程 A 再进行删除。所以，线程 A sleep 的时间，就需要大于线程 B 读取数据再写入缓存的时间。这个时间怎么确定呢？建议你在业务程序运行的时候，统计下线程读数据和写缓存的操作时间，以此为基础来进行估算。这样一来，其它线程读取数据时，会发现缓存缺失，所以会从数据库中读取最新值。因为这个方案会在第一次删除缓存值后，延迟一段时间再次进行删除，所以我们也把它叫做“延迟双删”。

## 6.2.先更新数据库值,再删除缓存值

如果线程 A 删除了数据库中的值，但还没来得及删除缓存值，线程 B 就开始读取数据了，那么此时，线程 B 查询缓存时，发现缓存命中，就会直接从缓存中读取旧值。不过，在这种情况下，如果其他线程并发读缓存的请求不多，那么，就不会有很多请求读取到旧值。而且，线程 A 一般也会很快删除缓存值，这样一来，其他线程再次读取时，就会发生缓存缺失，进而从数据库中读取最新值。所以，这种情况对业务的影响较小。

<img src="https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210720111052314.png" alt="image-20210720111052314" style="zoom: 33%;" />

**解决方案:重试缓存删除**

重试机制,把删除的缓存自或者是要更新的数据库值展示存到消息队列中,当引用没有成功删除缓存或者是更新数据库值时候,可以从消息队列中读取这些值,然后再次进行删除或更新;如果成功地删除或更新,需要把这些值从消息队列中删除,意面重复操作.否则还需要进行重试,如果重试超过一定的次数,还是没有成功,就需要向业务层发送报错信息了.

![image-20210720105204818](https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210720105204818.png)

## 6.3.解决方案总结

对于读写缓存来说，如果我们采用同步写回策略，那么可以保证缓存和数据库中的数据一致。只读缓存的情况比较复杂，如下:

<img src="https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210720111502401.png" alt="image-20210720111502401" style="zoom:50%;" />

如果业务层要求必须读取一致的数据,那么我们就需要在更新数据库的时候,先在Redis缓存客户端暂存并发请求,等数据库更新完,缓存值删除后,再读取数据,保证数据一致性.

# 7.Redis的并发竞争问题

![image-20200527171057865](https://fechin-leyou.oss-cn-beijing.aliyuncs.com/PicGo/image-20200527171057865.png)

# 8.Redis主从复制

## 8.1.主从复制核心机制

1. redis采用异步方式复制数据到slave节点,不过redis2.8开始,slave node会周期性地确认自己每次复制的数据量;
2. 一个master node是可以配置多个slave node的,slave node也可以连接其他的slave node;
3. slave node做复制的时候,是不会block master node的正常工作的;
4. slave node在做复制的时候,也不会block对自己的查询操作,它会用旧的数据来提供服务,但是复制完成的时候,需要删除旧数据集,这个时候就会暂停对外服务了;
5. slave node主要用来横向扩容,做读写分离,扩容的slave node可以提高读的吞吐量;

## 8.2.主从复制流程

1. 当启动一个slave node的时候,slave node会发送一个PSYNC命令给master node;

2. 如果这是slave node重新连接master node,那么master node仅仅会复制给slave部分缺少的数据;否则如果是slave node第一次连接master node,那么会触发一次full resynchronization;

3. 开始full resynchronization的时候,master会启动一个后台线程,开始生成一份RDB快照文件,同时还会将从客户端收到的所有写命令缓存在内存中.RDB文件生成完毕后,master会将这个RDB发送给slave,slave会先写入本地磁盘,然后再从本地磁盘加载到内存中.然后master会将内存中新缓存的写命令直接发送到slave,slave也会同步这些数据;

4. slave node如果跟master node有网络故障,断开了连接,会自动重连;

5. master 如果有多个slave node,仅仅会启动一个rdb save操作,用一份数据服务所有slave;

6. 从redis 2.8开始,就支持主从复制的断点续传,如果主从复制过程中,网络连接断掉了,可以接着上次复制的地方,继续复制下去;

7. redis支持无磁盘化复制,master在内存中 直接创建rdb,然后发送给slave,不会在自己本地落地磁盘了.在conf文件中做如下修改:

   ```shell
   repl-diskless-sync yes #开启无磁盘化复制
   repl-diskless-sync-delay 5 #等待一定时长再开始复制,因为要等待更多slave重新
   ```

8. slave不会过期key,只会等待master过期key.如果master过期了一个key,或者通过LRU淘汰了一个key,那么会模拟一条del命令发送给slave;

## 8.3.主从复制的细节概念

1. master和salve都会维护一个offset

   master会在自身不断累加offset,slave也会在自身不断累加offset.slave每秒都会上报自己的offset给master,同时master也会保存每个slave的offset;

2. backlog

   master node有一个backlog,默认是1MB大小,master node给slave node复制数据时,也会将数据在backlog中同步写一份
   backlog主要是用来做全量复制中断候的增量复制的;

3. runid

   如果根据host+ip定位master node,是不靠谱的,如果master node重启或者数据出现了变化,那么slave node应该根据不同的run id区分,run id不同就做全量复制.

### 8.3.1.全量复制

1. master执行bgsave,在本地生成一份rdb快照文件;
2. master node将rdb快照文件发送给salve node,如果rdb复制时间超过60秒(repl-timeout),那么slave node就会认为复制失败,可以适当调节大这个参数;
3. 对于千兆网卡的机器,一般每秒传输100MB,6G文件,很可能超过60s;
4. master node在生成rdb时,会将所有新的写命令缓存在内存中,在salve node保存了rdb之后,再将新的写命令复制给salve node;
5. client-output-buffer-limit slave 256MB 64MB 60,如果在复制期间,内存缓冲区持续消耗超过64MB,或者一次性超过256MB,那么停止复制,复制失败;
6. slave node接收到rdb之后,清空自己的旧数据,然后重新加载rdb到自己的内存中;
7. 如果slave node开启了AOF,那么会立即执行BGREWRITEAOF,重写AOF;

### 8.3.2.增量复制

1. 如果全量复制过程中,master-slave网络连接断掉,那么salve重新连接master时,会触发增量复制;
2. master直接从自己的backlog中获取部分丢失的数据,发送给slave node,默认backlog就是1MB;
3. msater就是根据slave发送的psync中的offset来从backlog中获取数据的;

### 8.3.3.异步复制

master每次接收到写命令之后,先在内部写入数据,然后异步发送给slave node;

## 8.4.主从复制与读写分离  

* 主从复制可以用来支持读写分离;
* slave服务器设定为只读,可以用在数据安全的场景下;
* 可以使用主从复制来避免master持久化造成的开销.master关闭持久化,slave配置为RDB或是启用AOF.(注意:重新启动master程序将从一个空数据集开始,如果一个slave试图与它同步,那么这个slave也会被清空);

![image-20200526163746659](https://fechin-leyou.oss-cn-beijing.aliyuncs.com/PicGo/image-20200526163746659.png)

## 8.5.主从复制的问题

* 读写分离场景:
  * 数据复制延迟导致读到过期数据或者读不到数据(网络原因,slave阻塞);
* 全量复制的情况下:
  * 第一次建立主从关系或者runid不匹配会导致全量复制;
  * 故障转移的时候也会出现全量复制;
* 复制风暴:
  * master故障重启,如果slave节点较多,所有slave都要复制,对服务器的性能,网络的压力都有很大影响;
* 写能力有限:
  * 主从复制只有一台master,提供的写服务能力有限;
* master故障情况下:
  * 如果master无持久化,slave开启持久化来保留数据的场景,建议不要配置redis的自动重启;
  * 如果redis自动重启,master启动后,无备份数据,可能导致集群数据丢失的情况;

# 9.Redis高可用哨兵模式(Sentinel)

## 9.1.哨兵介绍

sentinel,中文哨兵.主要功能如下:

1. 集群监控:负责监控redis master和slave进程是否正常工作;
2. 消息通知:如果某个redis实例有故障,那么哨兵负责发送消息作为报警通知给管理员; 
3. 故障转移:如果master node挂了,会自动转移到slave node上;
4. 配置中心,如果故障转移发生了,通知client客户端新的master地址;  

## 9.2.哨兵部署

* 哨兵至少需要3个实例,来保证自己的健壮性;
* 哨兵+redis主从的部署架构是不会保证数据零丢失的,只能保证redis集群的高可用性;

> 1. 为什么redis哨兵集群只有2个节点无法正常工作?
>
>    哨兵集群必须部署2个以上节点.如果哨兵集群仅仅部署了2个哨兵实例,quorum=1;
>
>    <img src="https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210718185117321.png" alt="image-20210718185117321" style="zoom: 50%;" />
>
>    Configuration:`quorum=1`;master宕机,s1和s2中只要有1个哨兵认为master宕机就可以进行切换,同时s1和s2中会选举出一个哨兵来执行故障转移;同时这个时候,需要majority,也就是大多数哨兵都是运行的,2个哨兵的majority就是2(2的majority=2,3的majority=2,4的majority=2,5的majority=3),2个哨兵都运行着,就可以允许执行故障转移,如果整个M1和S1宕机了,那么哨兵只有1个,只是就没有majority来允许执行故障转移.
>
> 2. 3节点哨兵集群;
>
>    <img src="https://fechin-picgo.oss-cn-shanghai.aliyuncs.com/PicGo/image-20210718185720889.png" alt="image-20210718185720889" style="zoom:50%;" />
>
>    Configuration:`quorum=2,majority=2`,如果M1所在的机器宕机了,那么三个哨兵还剩下2个,S2和S3可以一致认为master宕机,然后选举出来一个执行故障转移;同时majority是2,还剩下2个哨兵运行着,就可以允许执行故障转移;

## 9.3.quorum和majority

* 每次一个哨兵要做主备切换,首先需要quorum数量的哨兵认为odown,然后选举出一个哨兵来做切换,这个哨兵还得得到majority哨兵的授权,才能正式执行切换;
* 如果quorum < majority,比如5个哨兵,majority就是3,quorum设置为2,那么就3个哨兵授权就可以执行切换;
* 但是如果quorum >= majority,那么必须quorum数量的哨兵都授权,比如5个哨兵,quorum是5,那么必须5个哨兵都同意授权,才能执行切换;

## 9.4.哨兵sdown和odown

启动命令`redis-server /path/to/sentinel.conf --sentinel`;

配置文件启动时指定,运行过程中会自动变更,记录哨兵的监测结果;

![image-20200526204137815](https://fechin-leyou.oss-cn-beijing.aliyuncs.com/PicGo/image-20200526204137815.png)

* 哨兵如何知道Redis主从信息?
  * 哨兵配置文件中,保存着主从集群中master的信息,可以通过info命令,进行主从信息自动发现;
* 什么是主观下线(sdown)?
  * 主观下线:单个哨兵自身认为Redis实例已经不能提供服务;
  * 监测机制:哨兵向Redis发送PING请求,+PONG,-LOADING,-MASTERDOWN这三种情况视为正常,其他回复均视为无效;
* 什么是客观下线(odown)?
  * 客观下线:一定数量值的哨兵认为master已经下线;
  * 监测机制:则会通过`SENTINEL is-master-down-by-addr`命令询问其他哨兵是否认为master已经下线,如果达成共识(达到quorum个数),就会认为master节点客观下线,开始故障转移流程;

## 9.5.哨兵和slave集群的自动发现机制

* 哨兵互相之间的发现,是通过redis的pub/sub系统实现的,每个哨兵都会往__sentinel__:hello这个channel里发送一个消息,这时候所有其他哨兵都可以消费到这个消息,并感知到其他的哨兵的存在;

* 每隔两秒钟,每个哨兵都会往自己监控的某个master+slaves对应的__sentinel__:hello channel里发送一个消息,内容是自己的host、ip和runid还有对这个master的监控配置;

* 每个哨兵也会去监听自己监控的每个master+slaves对应的__sentinel__:hello channel,然后去感知到同样在监听这个master+slaves的其他哨兵的存在;

* 每个哨兵还会跟其他哨兵交换对master的监控配置,互相进行监控配置的同步;

![image-20200526210158691](https://fechin-leyou.oss-cn-beijing.aliyuncs.com/PicGo/image-20200526210158691.png)

## 9.6.哨兵领导选举机制

基于Raft算法实现的选举机制,流程如下:

1. 拉票阶段:每个哨兵节点希望自己成为领导者;
2. sentinel节点收到拉票命令后,如果没有收到或同意过其他sentinel节点的请求,就同意该sentinel节点的请求(每个sentinel只持有一个同意票数);
3. 如果sentinel节点发现自己的票数已经超过一般的数值,那么它将成为领导者,去执行故障转移;
4. 投票结束后,如果超过failover-timeout的时间内,没有进行实际的故障转移操作,则重新拉票选举;

![image-20200526211208801](https://fechin-leyou.oss-cn-beijing.aliyuncs.com/PicGo/image-20200526211208801.png)

## 9.7.Slave->Master选举算法

 如果一个master被认为odown了,而且majority哨兵都允许了准备切换,此时首先要选举一个slave来.会考虑slave的一些信息;如下顺序有优先级

1. 如果一个slave根master断开时间已经超过了`(down-after-milliseconds*10)+milliseconds_since_master_is_in_SDOWN_state`即down-after-milliseconds的10倍,外加master宕机的时长,那么slave就被认为不适合选举为master.
2. `slave-priority`值越小,优先级越高;
3. 如果`slave-priority`相同,看replica offset,哪个slave复制了越多的数据,offset越靠后,优先级就越高;
4. 如果上述条件都相同,选择 run id比较小的slave;

![image-20200526211950920](https://fechin-leyou.oss-cn-beijing.aliyuncs.com/PicGo/image-20200526211950920.png)

最终主从切换过程
* 针对即将成为master的slave节点,将其撤出主从集群,自动执行:`slaveof no one`;
* 针对其他slave节点,使他们成为新master的从属,自动执行:`slaveof new_master_host new_master_port`;

## 9.8.哨兵模式数据丢失和解决方案

### 9.8.1.数据丢失的情况

1. 异步复制导致的数据丢失;

   因为master --> slave的复制是异步的,所以可能有部分数据还没复制到slave,master就宕机了,此时这些部分数据就丢失了;

2. 脑裂导致的数据丢失;

   某个master所在机器突然脱离了正常的网络,跟其他slave机器不能连接,但是实际上master还运行着.此时哨兵可能就会认为master宕机了,然后开启选举,将其他slave切换成了master.这个时候,集群里就会有两个master,脑裂.此时虽然某个slave被切换成了master,但是可能client还没来得及切换到新的master,还继续写向旧master的数据可能也丢失了.因此旧master再次恢复的时候,会被作为一个slave挂到新的master上去,自己的数据会清空,重新从新的master复制数据;

### 9.8.2.减少异步复制和脑裂导致的数据丢失

~~~shell
min-slaves-to-write 1 
min-slaves-max-lag 10
#要求至少有1个slave,数据复制和同步的延迟时间不能超过10s;如果说一旦所有的slave,数据复制和同步的延迟都超过了10s,那么这个时候,master就不会再接收任何请求了.
~~~

1. 减少异步复制的数据丢失:

   有了min-slaves-max-lag这个配置,一旦slave复制数据和ack延时太长,就认为可能master宕机后损失的数据太多了,那么就拒绝写请求,这样可以把master宕机时由于部分数据未同步到slave导致的数据丢失降低的可控范围内;

2. 减少脑裂的数据丢失:

   如果一个master出现了脑裂,跟其他slave丢了连接,如果不能继续给指定数量的slave发送数据,而且slave超过10秒没有给自己ack消息,那么就直接拒绝客户端的写请求,这样脑裂后的旧master就不会接受client的新数据,也就避免了数据丢失,上面的配置就确保了,如果跟任何一个slave丢了连接,在10秒后发现没有slave给自己ack,那么就拒绝新的写请求,因此在脑裂场景下,最多就丢失10秒的数据.


# 10.Redis高可用Cluster模式

Redis cluster支撑N个redis master node,每个master node都可以挂载多个salve node.对于每个master来说,写就写到master,读就到从master对应的slave去读;

## 10.1.官方集群方案

redis cluster是Redis的分布式集群解决方案,在3.0版本推出后有效地解决了redis分布式方面的需求,实现了数据在多个Redis节点之间自动分片,故障自动转移,扩容机制等功能;

![image-20200526214113624](https://fechin-leyou.oss-cn-beijing.aliyuncs.com/PicGo/image-20200526214113624.png)

![image-20200526220401387](https://fechin-leyou.oss-cn-beijing.aliyuncs.com/PicGo/image-20200526220401387.png)

## 10.2.Hash算法

对key进行计算hash值,然后对master节点数量取模.最大的问题,任意一个master宕机,那么大量的数据就需要重新计算写入缓存,风险极大;

## 10.3.一致性Hash算法

可参考https://www.cnblogs.com/lpfuture/p/5796398.html;

## 10.4.Hash Slot算法

* redis cluster有固定的16384个hash slot，对每个key计算CRC16值，然后对16384取模，可以获取key对应的hash slot;
* redis cluster中每个master都会持有部分slot，比如有3个master，那么可能每个master持有5000多个hash slot;
* hash slot让node的增加和移除很简单，增加一个master，就将其他master的hash slot移动部分过去，减少一个master，就将它的hash slot移动到其他master上去,移动hash slot的成本是非常低的;
* 如果有3个master节点,任何一台机器宕机,另外两个节点,不影响,因为key找的是hash slot,找的不是机器;
* 客户端的api，可以对指定的数据，让他们走同一个hash slot，通过hash tag来实现;

## 10.5.节点间的内部通信机制

Redis cluster节点采用gossip协议进行通信;跟集中式不同,不是将集群元数据集中存储在节点上,而是互相之间不断通信,保持整个集群所有节点都是完整的.

维护集群的元数据一般有两种:

1. 集中式:好处在于，元数据的更新和读取，时效性非常好，一旦元数据出现了变更，立即就更新到集中式的存储中，其他节点读取的时候立即就可以感知到; 不好在于，所有的元数据的跟新压力全部集中在一个地方，可能会导致元数据的存储有压力;
2. gossip:好处在于，元数据的更新比较分散，不是集中在一个地方，更新请求会陆陆续续，打到所有节点上去更新，有一定的延时，降低了压力; 缺点，元数据更新有延时，可能导致集群的一些操作会有一些滞后;

## 10.6.面向cluster集群的jedis内部实现原理

* 基于重定向的客户端
  * 请求重定向
    * 客户端可能回挑选任意一个redis实例去发送命令,每个redis实例接收到命令,都会计算对应的hash slot;如果在本地就在本地处理,否则返回moved给客户端,让客户端重定向;
    * `cluster keyslot mykey`可以查看一个key对应的hash slot是什么
    * 用redis-cli的时候可以加`-c`参数,支持自动的请求重定向,redis-cli接收到moved之后,会自动重定向到对应的节点执行命令;
  * 计算hash slot
    * 计算hash slot的算法,就是根据key计算CRC16值,然后对16384取模,拿到对应的hash slot;
    * 用hash tag可以手动指定key对应的slot,同一个hash tag下的key,都会在一个hash slot中,比如`set mykey1:{100}`和`set mykey2:{100}`;
  * hash slot查找
    * 节点间通过gossip协议进行数据交换,就知道每个hash slot在哪个节点上;

* smart jedis

  * smart jedis工作原理
    * 基于重定向的客户端,很消耗网络IO,因为大部分情况下,可能都会出现一次请求重定向,才能找到正确的节点;
    * 大部分的客户端,如java redis客户端jedis就是smart的;
    * 本地维护一份hashslot -> node的映射表,缓存,大部分情况下,直接走本地缓存就可以找到hashslot -> node;

  * JedisCluster的工作原理
    * 在JedisCluster初始化的时候，就会随机选择一个node，初始化hashslot -> node映射表，同时为每个节点创建一个JedisPool连接池.每次基于JedisCluster执行操作，首先JedisCluster都会在本地计算key的hashslot，然后在本地映射表找到对应的节点.如果那个node正好还是持有那个hashslot，那么就ok; 如果说进行了reshard这样的操作，可能hashslot已经不在那个node上了，就会返回moved.如果JedisCluter API发现对应的节点返回moved，那么利用该节点的元数据，更新本地的hashslot -> node映射表缓存.重复上面几个步骤，直到找到对应的节点，如果重试超过5次，那么就报错，JedisClusterMaxRedirectionException.jedis老版本，可能会出现在集群某个节点故障还没完成自动切换恢复时，频繁更新hash slot，频繁ping节点检查活跃，导致大量网络IO开销.jedis最新版本，对于这些过度的hash slot更新和ping，都进行了优化，避免了类似问题.
  * hashslot迁移和ask重定向
    * 如果hash slot正在迁移，那么会返回ask重定向给jedis;
    * jedis接收到ask重定向之后，会重新定位到目标节点去执行，但是因为ask发生在hash slot迁移过程中，所以JedisCluster API收到ask是不会更新hashslot本地缓存
    * 已经可以确定说，hashslot已经迁移完了，moved是会更新本地hashslot->node映射表缓存的

## 10.7.高可用性与主备切换的原理

redis cluster的高可用的原理,几乎与哨兵类似:

* 判断节点宕机
  * 如果一个节点认为另外一个节点宕机，那么就是pfail，主观宕机
  * 如果多个节点都认为另外一个节点宕机了，那么就是fail，客观宕机，跟哨兵的原理几乎一样，sdown，odown
  * 在cluster-node-timeout内，某个节点一直没有返回pong，那么就被认为pfail
  * 如果一个节点认为某个节点pfail了，那么会在gossip ping消息中，ping给其他节点，如果超过半数的节点都认为pfail了，那么就会变成fail
* 从节点过滤
  * 对宕机的master node，从其所有的slave node中，选择一个切换成master node
  * 检查每个slave node与master node断开连接的时间，如果超过了`cluster-node-timeout * cluster-slave-validity-factor`，那么就没有资格切换成master
  * 这个也是跟哨兵是一样的，从节点超时过滤的步骤

* 从节点选举
  * 哨兵：对所有从节点进行排序，slave priority，offset，run id
  * 每个从节点，都根据自己对master复制数据的offset，来设置一个选举时间，offset越大（复制数据越多）的从节点，选举时间越靠前，优先进行选举
  * 所有的master node开始slave选举投票，给要进行选举的slave进行投票，如果大部分master node（N/2 + 1）都投票给了某个从节点，那么选举通过，那个从节点可以切换成master
  * 从节点执行主备切换，从节点切换为主节点

* 与哨兵比较
  * 整个流程跟哨兵相比，非常类似，所以说，redis cluster功能强大，直接集成了replication和sentinal的功能



